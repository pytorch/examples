{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1GqTjeV47m4B"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KpuvHS0mxwCd"
   },
   "source": [
    "## Data Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eYrAa5laSptM"
   },
   "source": [
    "### Alphabets Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "-a04ZKx7Sh-J",
    "outputId": "35b3c4d6-6f66-46d9-9d64-45b6fad1179a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
     ]
    }
   ],
   "source": [
    "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "pad_char = '-PAD-'\n",
    "\n",
    "eng_alpha2index = {pad_char: 0}\n",
    "for index, alpha in enumerate(eng_alphabets):\n",
    "    eng_alpha2index[alpha] = index+1\n",
    "\n",
    "print(eng_alpha2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "cPSZsy1kXd9w",
    "outputId": "547d24d3-b243-4934-ae12-b5d8c4fb11d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
     ]
    }
   ],
   "source": [
    "# Hindi Unicode Hex Range is 2304:2432. \n",
    "\n",
    "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
    "hindi_alphabet_size = len(hindi_alphabets)\n",
    "\n",
    "hindi_alpha2index = {pad_char: 0}\n",
    "for index, alpha in enumerate(hindi_alphabets):\n",
    "    hindi_alpha2index[alpha] = index+1\n",
    "\n",
    "print(hindi_alpha2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SSw1SMZmx9A3"
   },
   "source": [
    "### Helper functions for data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OcS6ByndOxrC"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
    "\n",
    "# Remove all English non-letters\n",
    "def cleanEnglishVocab(line):\n",
    "    line = line.replace('-', ' ').replace(',', ' ').upper()\n",
    "    line = non_eng_letters_regex.sub('', line)\n",
    "    return line.split()\n",
    "\n",
    "# Remove all Hindi non-letters\n",
    "def cleanHindiVocab(line):\n",
    "    line = line.replace('-', ' ').replace(',', ' ')\n",
    "    cleaned_line = ''\n",
    "    for char in line:\n",
    "        if char in hindi_alpha2index or char == ' ':\n",
    "            cleaned_line += char\n",
    "    return cleaned_line.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ob3F9Dh4PChB"
   },
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KGSeoMGg0FTy"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "class TransliterationDataLoader(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        self.eng_words, self.hindi_words = self.readXmlDataset(filename, cleanHindiVocab)\n",
    "        self.shuffle_indices = list(range(len(self.eng_words)))\n",
    "        random.shuffle(self.shuffle_indices)\n",
    "        self.shuffle_start_index = 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.eng_words)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.eng_words[idx], self.hindi_words[idx]\n",
    "    \n",
    "    def readXmlDataset(self, filename, lang_vocab_cleaner):\n",
    "        transliterationCorpus = ET.parse(filename).getroot()\n",
    "        lang1_words = []\n",
    "        lang2_words = []\n",
    "\n",
    "        for line in transliterationCorpus:\n",
    "            wordlist1 = cleanEnglishVocab(line[0].text)\n",
    "            wordlist2 = lang_vocab_cleaner(line[1].text)\n",
    "\n",
    "            # Skip noisy data\n",
    "            if len(wordlist1) != len(wordlist2):\n",
    "                print('Skipping: ', line[0].text, ' - ', line[1].text)\n",
    "                continue\n",
    "\n",
    "            for word in wordlist1:\n",
    "                lang1_words.append(word)\n",
    "            for word in wordlist2:\n",
    "                lang2_words.append(word)\n",
    "\n",
    "        return lang1_words, lang2_words\n",
    "    \n",
    "    def get_random_sample(self):\n",
    "        return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
    "    \n",
    "    def get_batch_from_array(self, batch_size, array):\n",
    "        end = self.shuffle_start_index + batch_size\n",
    "        batch = []\n",
    "        if end >= len(self.eng_words):\n",
    "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
    "            end = len(self.eng_words)\n",
    "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n",
    "    \n",
    "    def get_batch(self, batch_size, postprocess = True):\n",
    "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
    "        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n",
    "        self.shuffle_start_index += batch_size + 1\n",
    "        \n",
    "        # Reshuffle if 1 epoch is complete\n",
    "        if self.shuffle_start_index >= len(self.eng_words):\n",
    "            random.shuffle(self.shuffle_indices)\n",
    "            self.shuffle_start_index = 0\n",
    "            \n",
    "        return eng_batch, hindi_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 693
    },
    "colab_type": "code",
    "id": "-FCCi-SerZS-",
    "outputId": "4d00521a-466f-4bdd-a9c4-2cee71a37317"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping:  BARHARWA JUNCTION  -  बरहरवा\n",
      "Skipping:  STATE BNK TR  -  स्टेट बैंक ऑफ त्रावणकोर\n",
      "Skipping:  SOUTH ARLINGTON CHURCH OF CHRIST  -  साउथ अर्लिंग्टन\n",
      "Skipping:  KING EDWARD VII  -  किंग एडवर्ड\n",
      "Skipping:  DIBANG VALLEY  -  दिबंगवैली\n",
      "Skipping:  ORDER OF VASA  -  ऑडर ऑफ़ द वासा\n",
      "Skipping:  AZAMNAGAR ROAD  -  आज़मनगर\n",
      "Skipping:  CAPE TOWN  -  केपटाउन\n",
      "Skipping:  NEW ZEALAND  -  न्यूज़ीलैंड\n",
      "Skipping:  SEA OF THE HEBRIDES  -  सी ऑफ हरब्रिड्‍स\n",
      "Skipping:  RAMCOIND  -  राम्को इंड\n",
      "Skipping:  KELVINGROVE ART GALLERY AND MUSEUM  -  केल्व‍िनग्रोव आर्ट एण्ड म्युज़ियम\n",
      "Skipping:  AUSTRALIAN NATIONAL UNIVERSITY  -  ऑस्ट्रेलियननेशनल यूनिवर्सिटी\n",
      "Skipping:  JAHAN AARA  -  जहाँआरा\n",
      "Skipping:  NAVABHARAT FERRO ALLOYS  -  नव भारत फ़ैरो अलॉय\n",
      "Skipping:  RAMA LINGESHWARA  -  रामालिंगेश्वर\n",
      "Skipping:  FAKHRUN NISA  -  फखरुन्निसा\n",
      "Skipping:  REDIFF.COM INDIA LIMITED  -  रेडिफ़ डॉट कॉम इंडिया लिमिटेड\n",
      "Skipping:  OMKARNATH THAKUR  -  ओंकार नाथ ठाकुर\n",
      "Skipping:  OPENTV  -  ओपन टीवी\n",
      "Skipping:  ENVOY COMMUNICATIONS GROUP  -  एन्वॉय कम्युनिकेशंस\n",
      "Skipping:  WAR OF THE HOLY LEAGUE  -  वार ऑफ होली लीग\n",
      "Skipping:  VAPARAISO CHURCH OF CHRIST  -  व्हापरासिओ\n",
      "Skipping:  PARIS CHARLES DE GAULLE  -  पेरिस रॉसे चार्ल्स डे ग्यूले\n",
      "Skipping:  PARKWAY APOSTOLIC  -  पार्क वे अपोस्टोलिक\n",
      "Skipping:  MAUNA LOA  -  मौनालोआ\n",
      "Skipping:  MASS MUTUAL LIFE  -  मास म्युच्युअल लाइफ़ इंश्योरेंस\n",
      "Skipping:  STATS CHIPPAC  -  स्टेट्सचिपपैक\n",
      "Skipping:  NEWFOUNDLAND  -  न्यू फाउंडलैंड\n",
      "Skipping:  LONDONHEATHROW  -  लंदन हीथ्रो\n",
      "Skipping:  RETALIX  -  रेटालिक्स लि.\n",
      "Skipping:  SRISAILAM  -  श्री शैलम\n",
      "Skipping:  KARA-KUM  -  काराकुम\n",
      "Skipping:  WIND RIVER  -  विंडरिवर\n",
      "Skipping:  NETAJI SUBHASH CHANDRA BOSE  -  नेताजी सुभाषचंद्र बोस\n",
      "Skipping:  ROCKBROOK UNITED  -  रॉकब्रुक यूनाइटेड मेथोडिस्ट\n",
      "Skipping:  WALTER SCOTT  -  वॉल्टरस्कॉट\n",
      "Skipping:  COLOURPLUS FASHIONS  -  कलर प्लस फ़ैशन्स\n",
      "Skipping:  BAL KRISHNA  -  बालकृष्णा\n"
     ]
    }
   ],
   "source": [
    "train_data = TransliterationDataLoader('NEWS2012TrainingEnHi13937.xml')\n",
    "test_data = TransliterationDataLoader('NEWS2012RefEnHi1000.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7l-iaCVdx5Ez"
   },
   "source": [
    "### Basic Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "IjY06ghEx76b",
    "outputId": "a1ab9c6f-d18c-4cab-af4c-316550e7cf73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size:\t 20543\n",
      "Test Set Size:\t 1000\n",
      "\n",
      "Sample data from train-set:\n",
      "LOWELL - लोवेल\n",
      "STEW - स्टीव\n",
      "EAVAN - इवान\n",
      "KONGZHONG - काँगझाँग\n",
      "PLUNKETT - प्लंकेट\n",
      "COLES - कोल्स\n",
      "GURUDWARA - गुरूद्वारा\n",
      "ARVA - अर्वा\n",
      "MUMIN - मुमीन\n",
      "GANEE - गनी\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Set Size:\\t\", len(train_data))\n",
    "print(\"Test Set Size:\\t\", len(test_data))\n",
    "\n",
    "print('\\nSample data from train-set:')\n",
    "for i in range(10):\n",
    "    eng, hindi = train_data.get_random_sample()\n",
    "    print(eng + ' - ' + hindi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KpDP1_KYZIkv"
   },
   "source": [
    "### Encoding the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JE3at5C7Sy5F"
   },
   "outputs": [],
   "source": [
    "def word_rep(word, letter2index, device = 'cpu'):\n",
    "    rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n",
    "    for letter_index, letter in enumerate(word):\n",
    "        pos = letter2index[letter]\n",
    "        rep[letter_index][0][pos] = 1\n",
    "    pad_pos = letter2index[pad_char]\n",
    "    rep[letter_index+1][0][pad_pos] = 1\n",
    "    return rep\n",
    "\n",
    "def gt_rep(word, letter2index, device = 'cpu'):\n",
    "    gt_rep = torch.zeros([len(word)+1, 1], dtype=torch.long).to(device)\n",
    "    for letter_index, letter in enumerate(word):\n",
    "        pos = letter2index[letter]\n",
    "        gt_rep[letter_index][0] = pos\n",
    "    gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
    "    return gt_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "colab_type": "code",
    "id": "-yE3jToOrfzP",
    "outputId": "02979c41-e752-4dfb-982b-dc31fda77a45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANDOLKAR tensor([[[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "eng, hindi = train_data.get_random_sample()\n",
    "eng_rep = word_rep(eng, eng_alpha2index)\n",
    "print(eng, eng_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "uMcDjIberhc3",
    "outputId": "d8ab3a4d-5c20-4f8f-c764-0ae98c8c8b25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "चांदोरकर tensor([[27],\n",
      "        [63],\n",
      "        [ 3],\n",
      "        [39],\n",
      "        [76],\n",
      "        [49],\n",
      "        [22],\n",
      "        [49],\n",
      "        [ 0]])\n"
     ]
    }
   ],
   "source": [
    "hindi_gt = gt_rep(hindi, hindi_alpha2index)\n",
    "print(hindi, hindi_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GrC3tSnm4rUk"
   },
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D4OgdZ_DVVC5"
   },
   "source": [
    "### Encoder-Decoder (using GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6w8ffT3w4lkK"
   },
   "outputs": [],
   "source": [
    "MAX_OUTPUT_CHARS = 30\n",
    "class Transliteration_EncoderDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
    "        super(Transliteration_EncoderDecoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
    "        self.decoder_rnn_cell = nn.GRU(output_size, hidden_size)\n",
    "        \n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "        \n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
    "        \n",
    "        # encoder\n",
    "        out, hidden = self.encoder_rnn_cell(input)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('Encoder input', input.shape)\n",
    "            print('Encoder output', out.shape)\n",
    "            print('Encoder hidden', hidden.shape)\n",
    "        \n",
    "        # decoder\n",
    "        decoder_state = hidden\n",
    "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
    "        outputs = []\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('Decoder state', decoder_state.shape)\n",
    "            print('Decoder input', decoder_input.shape)\n",
    "        \n",
    "        for i in range(max_output_chars):\n",
    "            \n",
    "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print('Decoder intermediate output', out.shape)\n",
    "            \n",
    "            out = self.h2o(decoder_state)\n",
    "            out = self.softmax(out)\n",
    "            outputs.append(out.view(1, -1))\n",
    "            \n",
    "            if self.verbose:\n",
    "                print('Decoder output', out.shape)\n",
    "                self.verbose = False\n",
    "            \n",
    "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
    "            if not ground_truth is None:\n",
    "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
    "            one_hot = torch.FloatTensor(out.shape).to(device)\n",
    "            one_hot.zero_()\n",
    "            one_hot.scatter_(2, max_idx, 1)\n",
    "            \n",
    "            decoder_input = one_hot.detach()\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cra9toTiOoPm"
   },
   "outputs": [],
   "source": [
    "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I1OCzGyJlmXn"
   },
   "outputs": [],
   "source": [
    "def infer(model,word,max_output_chars,device='cpu'):\n",
    "  model.eval()\n",
    "  word_r = word_rep(word,eng_alpha2index,device)\n",
    "  out = model(word_r)\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "v4zaJq2pOrM8",
    "outputId": "7d1c36c6-de89-4066-8dd8-b6054c642339"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input torch.Size([6, 1, 27])\n",
      "Encoder output torch.Size([6, 1, 256])\n",
      "Encoder hidden torch.Size([1, 1, 256])\n",
      "Decoder state torch.Size([1, 1, 256])\n",
      "Decoder input torch.Size([1, 1, 129])\n",
      "Decoder intermediate output torch.Size([1, 1, 256])\n",
      "Decoder output torch.Size([1, 1, 129])\n"
     ]
    }
   ],
   "source": [
    "out = infer(net, 'INDIA', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AQ59zoHxvTgj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "1_pdzBmQOsjO",
    "outputId": "9e658218-eeca-46f2-8899-39ad1222a655"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "खखक़खक़खक़खक़खक़खक़खक़खक़खक़खक़खक़खक़खक़खक़ख\n"
     ]
    }
   ],
   "source": [
    "print(len(out))\n",
    "pred = ''\n",
    "for i in range(len(out)):\n",
    "  char = list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))]\n",
    "  if char == '-PAD-':\n",
    "    break\n",
    "  pred+=list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))]\n",
    "print(pred)\n",
    "#     print(list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NEg49N9e7oTY"
   },
   "source": [
    "### Encoder-Decoder with Attention \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8z-1QDAz8F_d"
   },
   "outputs": [],
   "source": [
    "class Transliteration_EncoderDecoder_Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
    "        super(Transliteration_EncoderDecoder_Attention, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
    "        self.decoder_rnn_cell = nn.GRU(hidden_size*2, hidden_size)\n",
    "        \n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "        \n",
    "        self.U = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.W = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size, 1)\n",
    "        self.out2hidden = nn.Linear(self.output_size, self.hidden_size)   \n",
    "        \n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
    "        \n",
    "        # encoder\n",
    "        encoder_outputs, hidden = self.encoder_rnn_cell(input)\n",
    "        encoder_outputs = encoder_outputs.view(-1, self.hidden_size)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('Encoder output', encoder_outputs.shape)\n",
    "        \n",
    "        # decoder\n",
    "        decoder_state = hidden\n",
    "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
    "        \n",
    "        outputs = []\n",
    "        U = self.U(encoder_outputs)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('Decoder state', decoder_state.shape)\n",
    "            print('Decoder intermediate input', decoder_input.shape)\n",
    "            print('U * Encoder output', U.shape)\n",
    "        \n",
    "        for i in range(max_output_chars):\n",
    "            \n",
    "            W = self.W(decoder_state.view(1, -1).repeat(encoder_outputs.shape[0], 1))\n",
    "            V = self.attn(torch.tanh(U + W))\n",
    "            attn_weights = F.softmax(V.view(1, -1), dim = 1) \n",
    "            \n",
    "            if self.verbose:\n",
    "                print('W * Decoder state', W.shape)\n",
    "                print('V', V.shape)\n",
    "                print('Attn', attn_weights.shape)\n",
    "            \n",
    "            attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "            \n",
    "            embedding = self.out2hidden(decoder_input)\n",
    "            decoder_input = torch.cat((embedding[0], attn_applied[0]), 1).unsqueeze(0)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print('Attn LC', attn_applied.shape)\n",
    "                print('Decoder input', decoder_input.shape)\n",
    "                \n",
    "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print('Decoder intermediate output', out.shape)\n",
    "                \n",
    "            out = self.h2o(decoder_state)\n",
    "            out = self.softmax(out)\n",
    "            outputs.append(out.view(1, -1))\n",
    "            \n",
    "            if self.verbose:\n",
    "                print('Decoder output', out.shape)\n",
    "                self.verbose = False\n",
    "            \n",
    "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
    "            if not ground_truth is None:\n",
    "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
    "            one_hot = torch.zeros(out.shape, device=device)\n",
    "            one_hot.scatter_(2, max_idx, 1) \n",
    "            \n",
    "            decoder_input = one_hot.detach()\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PMD3zjdJO0Oj"
   },
   "outputs": [],
   "source": [
    "net_attn = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YoiQwbntO5UH"
   },
   "outputs": [],
   "source": [
    "out = infer(net_attn, 'INDIA', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "colab_type": "code",
    "id": "K9WSPgzlO6k8",
    "outputId": "8d7910b1-76a7-4829-b30a-c262329f6480"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "torch.Size([1, 129]) ८\n",
      "torch.Size([1, 129]) ॓\n",
      "torch.Size([1, 129]) ८\n",
      "torch.Size([1, 129]) ॓\n",
      "torch.Size([1, 129]) ८\n",
      "torch.Size([1, 129]) ८\n",
      "torch.Size([1, 129]) ॓\n",
      "torch.Size([1, 129]) ८\n",
      "torch.Size([1, 129]) ॓\n",
      "torch.Size([1, 129]) ८\n",
      "torch.Size([1, 129]) ८\n",
      "torch.Size([1, 129]) ॓\n",
      "torch.Size([1, 129]) ८\n",
      "torch.Size([1, 129]) ॓\n",
      "torch.Size([1, 129]) ८\n",
      "torch.Size([1, 129]) ८\n",
      "torch.Size([1, 129]) ॓\n",
      "torch.Size([1, 129]) ८\n",
      "torch.Size([1, 129]) ॓\n",
      "torch.Size([1, 129]) ८\n",
      "torch.Size([1, 129]) ८\n",
      "torch.Size([1, 129]) ॓\n",
      "torch.Size([1, 129]) ८\n",
      "torch.Size([1, 129]) ॓\n",
      "torch.Size([1, 129]) ८\n",
      "torch.Size([1, 129]) ८\n",
      "torch.Size([1, 129]) ॓\n",
      "torch.Size([1, 129]) ८\n",
      "torch.Size([1, 129]) ॓\n",
      "torch.Size([1, 129]) ८\n"
     ]
    }
   ],
   "source": [
    "print(len(out))\n",
    "for i in range(len(out)):\n",
    "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cyE2tSnmAW6x"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H893cimDtTUE"
   },
   "source": [
    "### Core Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m804jsH7AXSV"
   },
   "outputs": [],
   "source": [
    "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
    "    \n",
    "    net.train().to(device)\n",
    "    opt.zero_grad()\n",
    "    eng_batch, hindi_batch = train_data.get_batch(batch_size)\n",
    "    \n",
    "    total_loss = 0\n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        input = word_rep(eng_batch[i], eng_alpha2index, device)\n",
    "        gt = gt_rep(hindi_batch[i], hindi_alpha2index, device)\n",
    "        outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n",
    "        \n",
    "        for index, output in enumerate(outputs):\n",
    "            loss = criterion(output, gt[index]) / batch_size\n",
    "            loss.backward(retain_graph = True)\n",
    "            total_loss += loss\n",
    "        \n",
    "    opt.step()\n",
    "    return total_loss/batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p-eZaBxstWz9"
   },
   "source": [
    "### Training Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rjto129ssrpr"
   },
   "outputs": [],
   "source": [
    "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
    "    \n",
    "    net = net.to(device)\n",
    "    criterion = nn.NLLLoss(ignore_index = -1)\n",
    "    opt = optim.Adam(net.parameters(), lr=lr)\n",
    "    teacher_force_upto = n_batches//3\n",
    "    \n",
    "    loss_arr = np.zeros(n_batches + 1)\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto ))/(i + 1)\n",
    "        \n",
    "        if i%display_freq == display_freq-1:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            print('Iteration', i, 'Loss', loss_arr[i])\n",
    "            plt.figure()\n",
    "            plt.plot(loss_arr[1:i], '-*')\n",
    "            plt.xlabel('Iteration')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.show()\n",
    "            print('\\n\\n')\n",
    "            \n",
    "    torch.save(net, 'model.pt')\n",
    "    return loss_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TZY6RvqLtdX8"
   },
   "source": [
    "### Training without Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1oQ3ZIWvtjfN"
   },
   "outputs": [],
   "source": [
    "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "colab_type": "code",
    "id": "E6LjVKQfoVMU",
    "outputId": "46bcb80b-66fb-4ea1-ea7d-fa8f5117231e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 269 Loss 0.013018195517361164\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xt81PWd7/HXJwkJIAQwBJVrUNAt\nZRU0grbdVkvrra6g6ypeOLb6eOjp1ranfXi6WOt5eFzZ1e3ZtlrdnnCqRdFWu1pbvLS2orZQFYlK\nFWlVigiEWsKdBEhI8jl//H6DwzAzmcx9Ju/n45EHM7/5zvD9Mcjb793cHRERkXRVFLoCIiJS2hQk\nIiKSEQWJiIhkREEiIiIZUZCIiEhGFCQiIpIRBYmIiGREQSIiIhlRkIiISEaqCl2BfBg5cqQ3NDQU\nuhoiIiXl1Vdf3eru9b2V6xdB0tDQQHNzc6GrISJSUszs/VTKqWtLREQyoiAREZGMKEhERCQjChIR\nEcmIgkRERDKiIEnBlt37uaTpJbbs2V/oqoiIFB0FSQruWvouK9dv565n3y10VUREik6/WEeSrhO+\n9Us6unoOPn9wxQYeXLGBmqoK3r7t3ALWTESkeKhFksSyb5zJBdNGU2EfXmuoG8yyfz6zcJUSESky\nCpIkRtUO5Mk/bKbHP7y2ftteZixYygnf+mXhKiYiUkQUJL345OSRDBxw6B/T2R89Sq0SEZGQgqQX\ni66eyeABhw4lrWttZ9TQgQWqkYhIcVGQpGD73s5Dnr+7pY2G+U+pe0tEBAVJUpH1I4MGVHDsyMHU\nVAV/XNWVxuxpo9W9JSKCpv8mdfsv/8TK97bjwJCaAXR27QXgQLcztKZK3VsiIihI4opdPwLwRssu\nKgzcYfr44bS2dRSodiIixUVdW3HEWz/SOGEEL984iwGVxoyJdTTNayxcBUVEioiCJI5RtQMZWlN1\nyPqRYYMGMKp2ICMGV7MzZvBdRKQ/U5AksLWtg8YJIw4+39vZDcCRR1SzvV1BIiISoSBJoGleI/90\n5nEHn3/7H08EYPjgAexQi0RE5CAFSRIT6o44+HjE4GogaJHs2HugUFUSESk6CpIkxo4YhAEGtHd0\nAUGg7FDXlojIQTkNEjM7x8zeNrO1ZjY/zus1ZvZI+PoKM2sIr9eZ2fNm1mZmd8e851Ize8PM3jKz\nO3JZ/5qqSgZXV+IEZ5JApEXSSU/0SLyISD+Ws3UkZlYJ3AN8FtgErDSzJe6+JqrYNcAOd59kZnOB\nO4BLgf3AzcDU8CfymXXAt4FT3L3VzO43s1nuvjTb9U90FklVhdHjsGd/F8MGD8j2bysiUnJy2SKZ\nAax193Xu3gk8DMyOKTMbuD98/Cgwy8zM3dvdfTlBoEQ7FnjX3VvD588C/5CLykfWkkS2RRk4oILZ\n00Zz8/kfAWDefSt09K6ICLkNkjHAxqjnm8Jrccu4exewC6hL8plrgRPMrMHMqoA5wLis1ThKZC1J\nZ3cPNVUVdHT1MLSm6uAA/JubdunoXRERSmyLFHffYWZfBB4BeoAXgePilTWza4FrAcaPH5/W77e1\nrYMrZk7g8hnj+fErG/jxivd5cMWGoC7o6F0REchtkLRwaGthbHgtXplNYQtjGLAt2Ye6+xPAE3Aw\nLLoTlFsILARobGxMa2Q8ehuU2+ZM5SufnsS3fr6aX6/5KxB0d5390aO56XMfSefjRUTKQi67tlYC\nk81soplVA3OBJTFllgBXhY8vBp5z96T/6JvZqPDXEcA/AT/Maq2TGFU7kPqhNUE9gP0Heqgy0y7A\nItKv5axF4u5dZnY98AxQCdzn7m+Z2a1As7svAe4FFpvZWmA7QdgAYGbrgVqg2szmAGeFM77uNLOT\nwmK3uvs7ubqHeLa2dfCRo4fypw/2APDK+u35/O1FRIqO9dIAKAuNjY3e3Nyclc+Kt8U8oHESESk7\nZvaqu/e61blWtvfRsm+cyd+feMzB55FpwTotUUT6KwVJH42qHUjtoGAhYoVxcFqwxklEpL8qqem/\nxWJrWwejhw1kUE0lpx87klYtTBSRfkxBkoameY38r1+s5uevt3DbnKm9v0FEpIypaytN40YMZvf+\nLnZpS3kR6ecUJGkad+RgADZs31vgmoiIFJaCJE3jwyD52k9XafNGEenXFCRpGnfkIADWbmnj/LuW\nK0xEpN/SYHsaYhclbtnTwYwFS7UoUUT6JbVI0rDsG2dSYYdf7+jq4fibns5/hURECkhBkoZRtQOZ\nMy32aJXA3580Os+1EREpLAVJmto7u5g8ashh1x97rYWG+U9xwrd+WYBaiYjkn4IkTU3zGvlza1vc\n1yoM7b0lIv2GgiQDL984iwumjT7sD/HC6WO095aI9BsKkgxEznXvgYOD75UG29o6ClovEZF8UpBk\naGtbB1eeNoEnv/x3DBpQQbfD2BGDC10tEZG80cFWWZDosKvqSuOdBefl7PcVEcklHWyVR8u+cSYX\nTBtNTdWhf5yaCiwi/YFWtmdBZKwktlXy2GstPPZai1a8i0hZU4skS7a2dXDRyWP41PH1h1xvqBus\nqcAiUtY0RpJlx974FD1x/kjVKhGRUlMUYyRmdo6ZvW1ma81sfpzXa8zskfD1FWbWEF6vM7PnzazN\nzO6Oec9lZvammb1hZr8ys5G5vIe++uTkkTTUHTprS60SESlnOQsSM6sE7gHOBaYAl5nZlJhi1wA7\n3H0S8F3gjvD6fuBm4IaYz6wC7gTOdPcTgTeA63N1D+lYdPXMww67Wr9tLzMWLNW2KSJSlnLZIpkB\nrHX3de7eCTwMzI4pMxu4P3z8KDDLzMzd2919OUGgRLPw5wgzM6AW2JyzO0hTbKukwmD2tNFqlYhI\nWcplkIwBNkY93xRei1vG3buAXUBdog909wPAF4E3CQJkCnBv9qqcHYuunsnHJ33Y4+bA0JoqbZsi\nImWppGZtmdkAgiCZDowm6Nq6MUHZa82s2cyaW1tb81jLwNa2Ds44IZjBNWzgADbt0NnuIlKechkk\nLcC4qOdjw2txy4TjH8OAbUk+cxqAu//Zg+lmPwU+Fq+guy9090Z3b6yvr49XJKea5jXy/cumA7Bz\n3wFtmyIiZSuXCxJXApPNbCJBYMwFLo8pswS4CngJuBh4zpPPR24BpphZvbu3Ap8F/pj1mmdB7LYp\nD67YwIMrNmgasIiUnZy1SMIxj+uBZwj+sf+pu79lZrea2QVhsXuBOjNbC3wdODhF2MzWA98BPm9m\nm8xsirtvBv438Dsze4OghfKvubqHTES2TRlQ+eGZvJoGLCLlSAsSc0iLE0WklBXFgsT+LjINONIo\n0TRgESlHCpIcikwDjrRK3DUNWETKj4Ikx7a2dXDJqcHktUHVlZoGLCJlR9vI51jTvKB78Tdr/sr2\n9k5NAxaRsqMgyTFNAxaRcqeurRyLTAOurgz+qKsrKzTgLiJlRUGSY5HTEw/0BK2Szu4eqsw04C4i\nZUNBkgdb2zq4YuYE6oZUA/DK+u0FrpGISPZojCQPXni79ZBxko079tEw/ykMWHHTLLVORKSkqUWS\nB5FxkpqqQ/+4Hbjr2XcLUykRkSxRiyQPIuMk0a2SCM3iEpFSpxZJnmxt6+Cik8cwdXTtYa/VVBqP\nfynubvgiIkVPQZInTfMa+c4l0zhp3PDDXuvods67c7nOdBeRkqQgybOtbR2MHhZ/cL2jq0dhIiIl\nR0GSZ03zGnnxxllcND32+HqdVyIipUmD7QXS3tmFEczcili/bS8zFiylutKYNn4Ed18+XVODRaTo\nqUVSIE3zGvnU8cF5JVUVH56iWFNVwWemHMXK9ds1NVhESoJOSCywRKcoRtPUYBEpBJ2QWCI+OXkk\nluT1mqoKTQ0WkaKmICmwRVfP5MI4A+8RHV09mhosIkVNQVIE2ju7mDxqSNKWiaYGi0ixUpAUgaZ5\njRxbfwRXnDaBp7/yd0ysO/wURXVxiUixymmQmNk5Zva2ma01s/lxXq8xs0fC11eYWUN4vc7Mnjez\nNjO7O6r8UDNbFfWz1cy+l8t7yJemeY3cNmcqU0bXcvzRQw9rnaiLS0SKVc6CxMwqgXuAc4EpwGVm\nNiWm2DXADnefBHwXuCO8vh+4GbghurC773H3aZEf4H3gZ7m6h0KJTA2O19WlLi4RKTa5bJHMANa6\n+zp37wQeBmbHlJkN3B8+fhSYZWbm7u3uvpwgUOIys+OBUcCy7Fe98BINwp/90aO0+l1Eikoug2QM\nsDHq+abwWtwy7t4F7ALqUvz8ucAjnmAhjJlda2bNZtbc2trap4oXi3iD8Ota27XaXUSKSikPts8F\nfpLoRXdf6O6N7t5YX1+fx2plT9O8Rv7c2nbINirvbmmjYf5T6t4SkaKRyyBpAcZFPR8bXotbxsyq\ngGHAtt4+2MxOAqrc/dXsVLV4vXzjLC6YNprqqNMVtbmjiBSTXAbJSmCymU00s2qCFsSSmDJLgKvC\nxxcDzyXqqopxGUlaI+VkVO1AnvzDZjqjTleMbO54/E1PF7BmIiKBnAVJOOZxPfAM8Efgp+7+lpnd\namYXhMXuBerMbC3wdeDgFGEzWw98B/i8mW2KmfF1Cf0kSCDYRqWhbjDVlYd+XUNqqrjwP3/Plj0J\n5ySIiOScNm0sETc9/iYPrdgQ97UKg3X/9rk810hEyp02bSwzkTPfLc7ikh5HA/AiUjAKkhIROfP9\nwmnxN3isqTTu/XwjlzS9xJrNu7ik6SV1eYlIXihISkxkbUmsjm7nyh++wivvbeerD6/SwVgikjca\nIylB1y1u5s1Nu9i8K7UWhw7GEpF0aIykjDXNa+TFG2dxUZJzTCK05kREck1BUsLaO7vibjkfLbLm\nRAPxIpIrKQWJmR1nZjXh4zPM7CtmNjy3VZPeNM1r5Pijhx42ZlIV861qo0cRyaVUWySPAd1mNglY\nSLCtyY9zVitJWeRQrCvDQ7GuPG0CRw8bdEiZ375TmptWikhpSGmw3cxec/eTzex/Avvd/ftm9rq7\nT899FTNXboPtvTn2xqfoifO1GrDiplnaPVhEUpLtwfYDZnYZwb5YT4bXBqRbOcmtl2+cRUWchYsO\nnPavS/NeHxEpb6kGyReA04EF7v6emU0EFueuWpKJUbUDmZNg4aJWwYtItqUUJO6+xt2/4u4/MbMR\nwFB3v6PXN0rBJJvRFb0KXqvfRSRTqY6RvABcAFQBrwJbgN+7+9dzWrss6W9jJBHXLW5mXWs7725p\nS1im7ohqjhk+kAGVFTTNO0XjJyJyULbHSIa5+27gIuABd58JfCaTCkruRWZ0jR6WOBy2tXeyumU3\nr2/YqS1VRCQtqQZJlZkdQ3AOyJO9FZbi0ZdV8A+u2EDD/Kd0YJaI9EmqQXIrwQFVf3b3lWZ2LKD/\nfS0hkc0e40zmOkztoAEaOxGRlGnTxn7kusXN1A8dyLrWNt7avItd+7qSlte6E5H+LdUxklQH28cC\n3wc+Hl5aBnzV3TdlVMs8UZAc7rrFzazZvJt9B7pp7+hi34GehGWnjqnVYLxIP5TtwfYfAUuA0eHP\nE+E1KVFN8xpZ9s+fpvlbn+Wik8cmLavBeBFJJtUgqXf3H7l7V/izCKjPYb0kj7a2dTBuxCDGH5l8\nJ2ENxotIPKkGyTYzu9LMKsOfK4FtuayY5E+kdfKRY4Zy5WkT+PQJyf8foXbQAB3nKyIHpTpGMoFg\njOR0gi2bXgS+7O4be3nfOcCdQCXwQ3e/Peb1GuAB4BSCYLrU3debWR3wKHAqsMjdr496TzVwN3AG\n0APc5O6PJauHxkj6JpWFjBFa0ChSvrI6RuLu77v7Be5e7+6j3H0O8A+9VKASuAc4F5gCXGZmU2KK\nXQPscPdJwHeByLYr+4GbgRvifPRNwBZ3Pz783N+mcg+SushCxnEjBjFySDWDBiT+axK9oPH8u5ar\nhSLSD6U9/dfMNrj7+CSvnw7c4u5nh89vBHD3f4sq80xY5iUzqwI+IBiP8fD1zwONMS2SjcDfuHt7\nqnVViyQzNz3+Jg+t2JByeU0bFikP+Tizvbe1bWOA6K6vTeG1uGXcvQvYBdQl/A0/PJXxX8zsNTP7\nLzM7KkHZa82s2cyaW1t1sFMmUh2Mj3Bg5oKlGkMR6ScyCZJCrGSsAsYCL7r7ycBLwP+JV9DdF7p7\no7s31tdrglkmYgfjP3ZcHcMGVSV9jwOvvLdd55+I9ANJ/zUwsz3EDwwDBsW5Hq2F4EjeiLHhtXhl\nNoVdW8NIPhtsG7AX+Fn4/L8IxlkkD5rmfdjCjSxo7OzuYc++A+xNsKAxcv5JdaXxzoLz8lVVEcmj\npEHi7kMz+OyVwOTwEKwWYC5weUyZJQSnLr4EXAw850kGbdzdzewJghlbzwGzgDUZ1FHSFBsqvc3y\niuzfpXETkfKT0722zOw84HsE03/vc/cFZnYr0OzuS8xsIMFJi9OB7cBcd18Xvnc9UAtUAzuBs9x9\nTTgVeTEwHGgFvuDuSUeCNdiee5EWyoljh/PUm39JWE4tE5HSkdW9tkqdgiS/Pn/fCta2trNpx764\nrytMREpDPmZticS16OqZfOr4xBMcOrtd26yIlBEFieREZMrwmOHx52R0djsT5z+l6cEiZUBBIjkR\nmTI8dUwtE+virz9xYMaCpQoTkRKnIJGcaprXyPFHD00YJhCEibq6REqXgkRyLhImk0cNSVhG4yYi\npUtBInkR2Qgy2Tb1ChOR0qQgkbxpmtfIbXOmMqCqImFXlwbhRUqPgkTyrrdxE236KFJaFCRSEKmE\nySvvbdesLpESoCCRgkllRhdoVpdIsVOQSEGlMqMLNBAvUswUJFJw0Uf7fu5vj0m6Gr5h/lNc+J+/\nV3eXSBFJfjqRSJ7EbktfXWm8t21v3LKvb9jJ7U//iU0793H35dO1Nb1IgalFIkUnlbGTn73ecnAw\nXi0UkcLSNvJStK5b3Mw7H+xJ2DKJNXVMLQMqK2iad4paKSJZoG3kpeSlOhAfsbplN69v2Mm531um\nVopIHilIpKhFD8QfVVvDhCMHM7DKkr5nW3snr2/YqUWNInmiri0pOamcER/rlZtmqbtLpI/UtSVl\nK7qVMv7I5IsZI2YsWKqpwyI5ohaJlLTrFjezZvNuOrt7aN/fRVtnd6/vqTuimvF1gzUoL9KLVFsk\nChIpG5FQOXHscFZt3EnLzn1Jyxtw0rjhmKFQEYmjKLq2zOwcM3vbzNaa2fw4r9eY2SPh6yvMrCG8\nXmdmz5tZm5ndHfOeF8LPXBX+jMrlPUjpiBzve88VJyc94jfCgVUbd/L6hp2cf9dydXmJpClnQWJm\nlcA9wLnAFOAyM5sSU+waYIe7TwK+C9wRXt8P3AzckODjr3D3aeHPluzXXkpdX6cOb9nTwYwFS3UW\nikgactkimQGsdfd17t4JPAzMjikzG7g/fPwoMMvMzN3b3X05QaCIpCV26vCQ6spe3+Og1fIifZTL\nvbbGABujnm8CZiYq4+5dZrYLqAO29vLZPzKzbuAx4DbvDwM9kpbYPbwiYyhvtuxiw/bEK+Yj61BO\nnXik9vMS6UUpbtp4hbu3mNlQgiCZBzwQW8jMrgWuBRg/fnx+ayhFKTZU3J0eJ+GgfPThWtPHD9eA\nvEgCuezaagHGRT0fG16LW8bMqoBhwLZkH+ruLeGve4AfE3ShxSu30N0b3b2xvr4+rRuQ8hUZmJ86\npjalcZTXN+xUl5dIArkMkpXAZDObaGbVwFxgSUyZJcBV4eOLgeeSdVOZWZWZjQwfDwDOB1ZnvebS\nb/R1caMCReRwOV1HYmbnAd8DKoH73H2Bmd0KNLv7EjMbCCwGpgPbgbnuvi5873qgFqgGdgJnAe8D\nvwMGhJ/5LPB1d0+6Ck3rSCQVWocicigtSIyiIJG+6ut+XlotL+WoKBYkipSqvnZ5RXYcnrFgqbq8\npN8pxVlbInkRmeUVmeFlZkmnDEfMWLAUA1Zox2HpJxQkIr2IDZRU1qE4MHPBUk4aN5yunh6d3Chl\nTWMkImmIDMyn2koBGDW0hkVfOJVbnlijRY5SEjTYHkVBIrkSCZRkCxvjUahIKVCQRFGQSK6lc2pj\nRN0R1RwzfKC6v6ToKEiiKEgkH/qyl1ciChUpJqkGiQbbRbIk3l5end097Nl3gL0HelL6jG3tnWxr\n7wTg9qf/xLqt7VrwKEVPLRKRHMuk2ytCCx6lENS1FUVBIoV23eJm6ocOZF1rG1vbOmjd00GPO7v2\ndfX5s7QTseSLgiSKgkSKUWRMpbO7h/b9XbR1Jt0y7jDTxw9nwZypmvklOaMgiaIgkWIXHSoDqyrZ\nsmc/+1IcVwEN0ktuKEiiKEik1KSz4DFC4ymSLdq0UaSERQ7e+sgxQ1PeODIiegPJNZt3cUnTS9pI\nUnJKLRKREpBJCwXUSpH0qGsrioJEykX0osfm97ezra2DrtSHUgDN+pLUKUiiKEikXGUy8+sVbXMv\nvVCQRFGQSH+QTvfXgAqYPuFITR+WuBQkURQk0p9EL358a/OulBY9avqwxKMgiaIgkf4qnVaKQkUi\ntGmjiBx2umMq56Zo40jpq5y2SMzsHOBOoBL4obvfHvN6DfAAcAqwDbjU3debWR3wKHAqsMjdr4/z\n2UuAY919am/1UItEJBDZQHLtljb6+l9+pKUCqLXSTxR8QaKZVQL3AOcCU4DLzGxKTLFrgB3uPgn4\nLnBHeH0/cDNwQ4LPvghIfytVkX6qaV4jx9YfwRWnTeBjx9UxbFDqnRLb2jtZ3bKb1S27eX3DTs6/\na7kWOgqQ266tGcBad18HYGYPA7OBNVFlZgO3hI8fBe42M3P3dmC5mU2K/VAzGwJ8HbgW+Gnuqi9S\nnmLPTUl3+vCWPR3MWLAUgKljatVK6cdyGSRjgI1RzzcBMxOVcfcuM9sF1AFbk3zuvwD/AfR9ea+I\nHCJRqPR148jVLbsBOPd7y7SCvh8qqcF2M5sGHOfuXzOzhl7KXkvQamH8+PG5r5xIiYsOFUhvxldk\noH7GgqVaQd+P5DJIWoBxUc/HhtfildlkZlXAMIJB90ROBxrNbD1B3UeZ2QvufkZsQXdfCCyEYLA9\nzXsQ6bdiZ3x1dvewe98BOrt66E7hv6jXN+xk5oKlnDRuOF09Per6KmO5DJKVwGQzm0gQGHOBy2PK\nLAGuAl4CLgae8yTTyNz9B8APAMIWyZPxQkREsideS6V+6EC2t3Xw9OoPkr7XgVUbdx58rq6v8pSz\nIAnHPK4HniGY/nufu79lZrcCze6+BLgXWGxma4HtBGEDQNjqqAWqzWwOcJa7r4n9fUQkv6JbKuNG\nDOrTQL26vsqTVraLSMbS3ebeQF1fRUxbpERRkIjkR/Q292+27ErrdEdtz1I8FCRRFCQi+ZfJGhX4\n8DCuBXOm8s3HV2ublgJQkERRkIgUVqYnPEaoxZJfCpIoChKR4pBp11e06BbLLU+s0ZkqOaAgiaIg\nESk+mXZ9xVJrJfsUJFEUJCLFTaFSnHQeiYiUjHh7fp04djjN729n654OqqsqUt73C+KfqdLVc+j7\nFTLZoxaJiBS9bLdYIkYNrWHRF07lm4+vPhg0CpgPqWsrioJEpHzEtli2tXXQlXpjJSXqGguoa0tE\nylKiXYqz2VrprWusvwdMLLVIRKRsZHKmSl/1h+nH6tqKoiAR6Z+ig2X3vgN0hH1gBilthd8X5dgd\npiCJoiARkWiRrfDXtbbxxqadHOh2KoyUz1rpTbmEisZIREQSiB1nichW11iiMZZSD5ZE1CIREUkg\nXtdYpt1ipdRaUddWFAWJiGRLNqcfF/uAvYIkioJERHIlm9OPi621oiCJoiARkXzI5vTj6FApVItF\nQRJFQSIihZCt1srkUUN4d0tb3lssCpIoChIRKbRS3OFY039FRIpIsh2O0xmwL6YpxjltkZjZOcCd\nQCXwQ3e/Peb1GuAB4BRgG3Cpu683szrgUeBUYJG7Xx/1nl8BxxCE4DLgS+6eNNrVIhGRYlasrZWC\nt0jMrBK4B/gssAlYaWZL3H1NVLFrgB3uPsnM5gJ3AJcC+4GbganhT7RL3H23mRlB2Pwj8HCu7kNE\nJNfitVYiA/Yf7N5Pd09Pn1os0a2Vu559l9su/NtsV/kQuezamgGsdfd1AGb2MDAbiA6S2cAt4eNH\ngbvNzNy9HVhuZpNiP9Tdd4cPq4BqoPwHeUSk34i36j6TFsuDKzbw4IoN1FRV8PZt52azqgflMkjG\nABujnm8CZiYq4+5dZrYLqAO2JvtgM3uGIKh+SRBAIiJlK1mLpbcpxhUGZ005ilvnxHbuZE9JDra7\n+9lmNhB4CPg08JvYMmZ2LXAtwPjx4/NbQRGRHOnreSw9DiOH1OR08D2XQdICjIt6Pja8Fq/MJjOr\nAoYRDLr3yt33m9kvCLrHDgsSd18ILIRgsL3PtRcRKQHJWiv7D3RTXVVBa1tHTuuQyyBZCUw2s4kE\ngTEXuDymzBLgKuAl4GLgOU8yjczMhgBD3f0vYfB8jmDmlohIv5doV+Ncy1mQhGMe1wPPEEz/vc/d\n3zKzW4Fmd18C3AssNrO1wHaCsAHAzNYDtUC1mc0BziJorSwJpw1XAM8D/zdX9yAiIr3TynYREYkr\n1XUkFfmojIiIlC8FiYiIZERBIiIiGVGQiIhIRvrFYLuZtQLvp/n2kfSy0r4M6B7Lg+6xPBTTPU5w\n9/reCvWLIMmEmTWnMmuhlOkey4PusTyU4j2qa0tERDKiIBERkYwoSHq3sNAVyAPdY3nQPZaHkrtH\njZGIiEhG1CIREZGMKEgSMLNzzOxtM1trZvMLXZ9sMbP1Zvamma0ys+bw2pFm9hszezf8dUSh69lX\nZnafmW0xs9VR1+LelwXuCr/bN8zs5MLVPHUJ7vEWM2sJv89VZnZe1Gs3hvf4tpmdXZhap87MxpnZ\n82a2xszeMrOvhtfL5ntMco+l/T26u35ifgh2K/4zcCzBcb5/AKYUul5Zurf1wMiYa/8OzA8fzwfu\nKHQ907ivTwInA6t7uy/gPILTNQ04DVhR6PpncI+3ADfEKTsl/HtbA0wM/z5XFvoeerm/Y4CTw8dD\ngXfC+yib7zHJPZb096gWSXwHz5t3904gct58uZoN3B8+vh+YU8C6pMXdf0dwFEG0RPc1G3jAAy8D\nw83smPzUNH0J7jGR2cDD7t5SZLEfAAAD6ElEQVTh7u8Bawn+Xhctd/+Lu78WPt4D/JHgOO6y+R6T\n3GMiJfE9Kkjii3fefLIvu5Q48GszezU8jhjgKHf/S/j4A+CowlQt6xLdV7l9v9eHXTv3RXVLlvQ9\nmlkDMB1YQZl+jzH3CCX8PSpI+p9PuPvJwLnAl8zsk9EvetCeLrupfOV6X8APgOOAacBfgP8obHUy\nF56E+hjwP9x9d/Rr5fI9xrnHkv4eFSTxpXLefEly95bw1y3A4wTN5L9GugTCX7cUroZZlei+yub7\ndfe/unu3u/cA/48Puz1K8h7NbADBP7APufvPwstl9T3Gu8dS/x4VJPEdPG/ezKoJjgBeUuA6ZczM\njjCzoZHHBMcXrya4t6vCYlcBvyhMDbMu0X0tAf5bOOvnNGBXVNdJSYkZE7iQ4PuE4B7nmlmNmU0E\nJgOv5Lt+fWFmRnD89h/d/TtRL5XN95joHkv+eyz0aH+x/hDMCHmHYJbETYWuT5bu6ViCGSB/AN6K\n3BdQBywF3gWeBY4sdF3TuLefEHQJHCDoR74m0X0RzPK5J/xu3wQaC13/DO5xcXgPbxD8o3NMVPmb\nwnt8Gzi30PVP4f4+QdBt9QawKvw5r5y+xyT3WNLfo1a2i4hIRtS1JSIiGVGQiIhIRhQkIiKSEQWJ\niIhkREEiIiIZUZCI9IGZtYW/NpjZ5Vn+7G/GPH8xm58vkisKEpH0NAB9ChIzq+qlyCFB4u4f62Od\nRApCQSKSntuBvwvPjviamVWa2bfNbGW48d51AGZ2hpktM7MlwJrw2s/DTTPfimycaWa3A4PCz3so\nvBZp/Vj42astOEvm0qjPfsHMHjWzP5nZQ+HKaZG86u3/kEQkvvkE50ecDxAGwi53P9XMaoDfm9mv\nw7InA1M92AYc4Gp3325mg4CVZvaYu883s+vdfVqc3+sigs38TgJGhu/5XfjadOCjwGbg98DHgeXZ\nv12RxNQiEcmOswj2fVpFsC14HcG+SACvRIUIwFfM7A/AywQb8k0muU8AP/FgU7+/Ar8FTo367E0e\nbPa3iqDLTSSv1CIRyQ4Dvuzuzxxy0ewMoD3m+WeA0919r5m9AAzM4PftiHrcjf6blgJQi0QkPXsI\njkqNeAb4YrhFOGZ2fLjDcqxhwI4wRP6G4IjYiAOR98dYBlwajsPUExy5W3w7wEq/pf97EUnPG0B3\n2EW1CLiToFvptXDAu5X4Rxb/CvjvZvZHgt1cX456bSHwhpm95u5XRF1/HDidYNdmB77h7h+EQSRS\ncNr9V0REMqKuLRERyYiCREREMqIgERGRjChIREQkIwoSERHJiIJEREQyoiAREZGMKEhERCQj/x+O\n69gJzOOHGAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-fed1ddbda443>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-a6aff6a6c25d>\u001b[0m in \u001b[0;36mtrain_setup\u001b[0;34m(net, lr, n_batches, batch_size, momentum, display_freq, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_force\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mteacher_force_upto\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdisplay_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdisplay_freq\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-dd7c11c925df>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(net, opt, criterion, batch_size, device, teacher_force)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_setup(net, lr=0.001, n_batches=2000, batch_size = 256, display_freq=10, device = device_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "-vS8xket6CB8",
    "outputId": "23dfc693-5263-448c-b774-7579b012bd04"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Transliteration_EncoderDecoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(net, 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pFFF9q0H6nlN"
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(),'weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GM1Tj20omMi1"
   },
   "source": [
    "### Training with Attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lxFLBqW1Ip4v"
   },
   "outputs": [],
   "source": [
    "net_att = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "colab_type": "code",
    "id": "tdRpJUXNIwuv",
    "outputId": "6e8ed733-4b95-4eae-ac09-be4f6a905d18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1999 Loss 0.1429685652256012\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nn7EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Transliteration_EncoderDecoderAttention_Type2. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "loss_history = train_setup(net_att, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = device_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "05F1-FwX6YVZ"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "B8Dp2neieM42",
    "outputId": "aaa523e5-61d3-456a-99fe-8b726784cb5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v3TWC7zhAn3z"
   },
   "outputs": [],
   "source": [
    "def test(net, word, device = 'cpu'):\n",
    "    net = net.eval().to(device)\n",
    "    out = infer(net, word, 30, device)\n",
    "    pred=''\n",
    "    for i in range(len(out)):\n",
    "      char = list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))]\n",
    "      if char == '-PAD-':\n",
    "        break\n",
    "      pred+=list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))]\n",
    "    print(word + ' - ' + pred)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hH1ZjVsFnHHg",
    "outputId": "6233b128-80c5-423c-fd29-56161401fda7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BHUBHANESHWAR - भुभेनश्वर\n"
     ]
    }
   ],
   "source": [
    "out = test(net,'BHUBHANESHWAR',device = \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-wda324_wf7U"
   },
   "outputs": [],
   "source": [
    "def test_sentence(net, sentence, device = 'cpu'):\n",
    "    \n",
    "    net = net.eval().to(device)\n",
    "    sentence = sentence.strip().upper().split(' ')\n",
    "    pred=''\n",
    "    for word in sentence:\n",
    "      out = infer(net, word, 30, device)\n",
    "\n",
    "      for i in range(len(out)):\n",
    "        char = list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))]\n",
    "        if char == '-PAD-':\n",
    "          break\n",
    "        pred+=char\n",
    "      pred+=' '\n",
    "    print(word + ' - ' + pred)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "LziF83qKw2GC",
    "outputId": "79bacb41-4b7f-4a0b-d6be-127a969d170e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA - मैं हूँ ना \n"
     ]
    }
   ],
   "source": [
    "sentence = 'mai hoon na'\n",
    "output = test_sentence(net,sentence,device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bT8bibYl7CgX"
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(net, device = 'cpu'):\n",
    "    net = net.eval().to(device)\n",
    "    predictions = []\n",
    "    accuracy = 0\n",
    "    for i in range(len(test_data)):\n",
    "        eng, hindi = test_data[i]\n",
    "        gt = gt_rep(hindi, hindi_alpha2index, device)\n",
    "        outputs = infer(net, eng, gt.shape[0], device)\n",
    "        correct = 0\n",
    "        for index, out in enumerate(outputs):\n",
    "            val, indices = out.topk(1)\n",
    "            hindi_pos = indices.tolist()[0]\n",
    "            if hindi_pos[0] == gt[index][0]:\n",
    "                correct += 1\n",
    "        \n",
    "        accuracy += correct/gt.shape[0]\n",
    "    accuracy /= len(test_data)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "colab_type": "code",
    "id": "dy1bQiORAs5o",
    "outputId": "8ad0a879-b81e-41cc-c155-2c1dbea7513f"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-b6bf29fe1637>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# accuracy_attn = calc_accuracy(net_att) * 100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy w/o attention '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print('Acurracy with attention', accuracy_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-969e6e082ff6>\u001b[0m in \u001b[0;36mcalc_accuracy\u001b[0;34m(net, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mhindi_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mhindi_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for dimension 0 with size 4"
     ]
    }
   ],
   "source": [
    "accuracy = calc_accuracy(net) * 100\n",
    "# accuracy_attn = calc_accuracy(net_att) * 100\n",
    "print('Accuracy w/o attention ', accuracy)\n",
    "# print('Acurracy with attention', accuracy_attn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ukoNAs8wP-GH"
   },
   "source": [
    "## Exercises\n",
    "\n",
    "1. Train longer and check accuracy - play with different hyperparameters\n",
    "2. Visualise attention - which part of the encoder output are we attending to\n",
    "3. Improve performance with batching - use the packing idea from earlier\n",
    "4. Try other attention mechanisms\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "IfCetNRGNkjW4FgAcQQh_0721_EncoderDecoderArchitecture-1563719382708.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
